#!/usr/bin/env python3
import pandas as pd
import json
import time
import random
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from openai import OpenAI

# ----------------------------
# CONFIGURATION
# ----------------------------
OPENAI_API_KEY = "YOUR_KEY"
INPUT_CSV = "prompts.csv"                # must contain 'prompt','category'
EXISTING_KEYWORDS_JSON = "keywords.json" # { "category":"[...]"}
OUTPUT_CSV = f"{datetime.now().strftime('%Y-%m-%d')}_keywords.csv"

client = OpenAI(api_key=OPENAI_API_KEY)

MAX_RETRIES = 5
INITIAL_BACKOFF = 1  # seconds


# ----------------------------
# STEP 1: Load prompts CSV
# ----------------------------
df = pd.read_csv(INPUT_CSV)
if "prompt" not in df.columns or "category" not in df.columns:
    raise ValueError("CSV must contain 'prompt' and 'category' columns")

groups = df.groupby("category")["prompt"].apply(list).to_dict()

# ----------------------------
# STEP 2: Load existing keyword JSON
# ----------------------------
try:
    with open(EXISTING_KEYWORDS_JSON, "r") as f:
        existing_keywords = json.load(f)
except FileNotFoundError:
    print("No existing keywords JSON found — starting fresh.")
    existing_keywords = {}


# ----------------------------
# LLM extraction with retry + backoff
# ----------------------------
def extract_keywords_with_retry(category, prompts):
    text_blob = "\n".join(prompts)
    prompt = f"""
    Here are user prompts from the '{category}' category:

    {text_blob}

    Extract 15-25 high-signal keywords and short keyphrases that represent
    this category. Do not include generic or conversational words.
    Return only a Python list of strings. No explanation.
    """

    backoff = INITIAL_BACKOFF

    for attempt in range(1, MAX_RETRIES + 1):
        try:
            res = client.responses.create(
                model="gpt-5",
                input=prompt,
            )

            # Try interpret output as a Python list
            return category, list(eval(res.output_text))

        except Exception as e:
            print(f"[{category}] Attempt {attempt}/{MAX_RETRIES} failed: {e}")
            if attempt == MAX_RETRIES:
                print(f"[{category}] ❌ All retries failed")
                return category, []

            # Exponential backoff with jitter
            sleep_time = backoff + random.uniform(0, 0.5)
            print(f"[{category}] Retrying in {sleep_time:.2f}s...")
            time.sleep(sleep_time)
            backoff *= 2


# ----------------------------
# STEP 3: Run concurrent extraction
# ----------------------------
results = []

with ThreadPoolExecutor(max_workers=6) as executor:
    futures = {
        executor.submit(extract_keywords_with_retry, cat, prompts): cat
        for cat, prompts in groups.items()
    }

    for future in as_completed(futures):
        category = futures[future]
        try:
            cat, new_keywords = future.result()
            new_keywords = set(new_keywords)
        except Exception as e:
            print(f"[{category}] Error retrieving results: {e}")
            continue

        old_keywords = set(existing_keywords.get(category, []))
        diff = new_keywords - old_keywords

        for kw in diff:
            results.append({"category": category, "new_keyword": kw})


# ----------------------------
# STEP 4: Save new keyword diff to CSV
# ----------------------------
if results:
    output_df = pd.DataFrame(results)
    output_df.to_csv(OUTPUT_CSV, index=False)
    print(f"✅ New keywords saved to {OUTPUT_CSV}")
else:
    print("✅ No new keywords discovered")


# ----------------------------
# STEP 5: Update JSON with new keywords
# ----------------------------
for row in results:
    cat = row["category"]
    kw = row["new_keyword"]
    existing_keywords.setdefault(cat, []).append(kw)

with open(EXISTING_KEYWORDS_JSON, "w") as f:
    json.dump(existing_keywords, f, indent=2)

print("✅ Updated keyword JSON file saved")
